---
title: "LM Link"
sidebar_title: "Introduction"
description: "Use LM Link to access your local models wherever you are, over a secure and end-to-end encrypted connection."
index: 1
---

<img src="/assets/docs/lmlink-animation.gif" style="width: 75%;" data-caption="Introducing LM Link" />

LM Link is a new feature in LM Studio that provides a way to access local models across devices, wherever you are. Links are custom made, end-to-end encrypted networks intended for loading and serving LLMs across devices you own, made possible in partnership with Tailscale. 

## What can I do with LM Link?
LM Link unlocks the full potential of your hardware by sharing compute across connected devices. For example, you might have a powerful desktop in your home office, and a lightweight laptop you carry on the go. With LM Link, you can run large open-weight models on a powerful machine, and use them seamlessly from your laptop as if they were local. All communication and data transfer between devices is always end-to-end encrypted, thanks to Tailscale. 

## Use Cases

LM Link use cases span individuals as well as teams. 

For individuals, manage a private link to keep your prized gaming GPU busy even when you're on the go. For teams, LM Link allows you to set up local LLM serving for multiple users with just a few clicks.

## Use LM Link with

- **CLI** — manage LM Link from the terminal with [`lms link`](/docs/cli/link/link-enable)
- **REST API** — use remote models via the REST API with [LM Link](/docs/rest-api/lmlink)
- **Integrations** — use remote models with coding tools like Claude Code and Codex via [LM Link](/docs/integrations/lmlink)
